{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Inference**\n",
        "---\n",
        "\n",
        "Putri Arzalya Maharani\n",
        "HCK-013\n",
        "\n",
        "Objective: Creating an inference to test the model"
      ],
      "metadata": {
        "id": "HkFZz540kPWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Libraries**"
      ],
      "metadata": {
        "id": "TfGueh5Ildae"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fOBpjjgokLCv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# preprocess\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from collections import Counter\n",
        "# model\n",
        "from tensorflow.keras.models import load_model\n",
        "# etc\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CWcF-dMkaJ1",
        "outputId": "15b2956d-77db-43e8-fb8a-b6775bfc7897"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load Model**"
      ],
      "metadata": {
        "id": "5W3z8oLblnkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopword_list= joblib.load('stopword_list.joblib')\n",
        "model = load_model('best_model.keras')"
      ],
      "metadata": {
        "id": "GHHvsXAGkdov"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Function for preprocessing**"
      ],
      "metadata": {
        "id": "hLyLW2ljlqMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wordnet_pos(treebank_tag):\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower() # lowercase text\n",
        "    tokens = word_tokenize(text) # tokenize\n",
        "    filtered_words = [word for word in tokens if word.lower() not in stopword_list]\n",
        "    lemmatized_words = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in filtered_words]\n",
        "    lemmatized_clean = [word.translate(str.maketrans('', '', string.punctuation)) for word in lemmatized_words]\n",
        "    return ' '.join(lemmatized_clean)\n",
        "\n",
        "def prediction(model, X):\n",
        "  y_pred = model.predict(X)\n",
        "  predictions = np.argmax(y_pred, axis=1)\n",
        "  for index, val in enumerate(predictions):\n",
        "    if val == 0:\n",
        "      print(f\"Text {index} indicates the person is feeling FEAR\")\n",
        "    elif val == 1:\n",
        "      print(f\"Text {index} indicates the person is feeling ANGER\")\n",
        "    else:\n",
        "      print(f\"Text {index} indicates the person is feeling JOY\")"
      ],
      "metadata": {
        "id": "_HP5LwdDkn7m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Input data for inference**"
      ],
      "metadata": {
        "id": "wwA4RszMlxYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input\n",
        "input1= 'I feel so happy, listening to my favorite music'\n",
        "input2= 'Exam is tommorow, im so nervous'\n",
        "input3= 'Devin is mad right now'"
      ],
      "metadata": {
        "id": "106vRRdokrko"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing\n",
        "x = preprocess_text(input1)\n",
        "y = preprocess_text(input2)\n",
        "z = preprocess_text(input3)"
      ],
      "metadata": {
        "id": "QaKC7lFhkuXw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting\n",
        "prediction(model, [x,y,z])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCHBVaI_kv5N",
        "outputId": "bb0dc508-219b-4bb9-f924-27b49e13be6a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "Text 0 indicates the person is feeling JOY\n",
            "Text 1 indicates the person is feeling FEAR\n",
            "Text 2 indicates the person is feeling ANGER\n"
          ]
        }
      ]
    }
  ]
}